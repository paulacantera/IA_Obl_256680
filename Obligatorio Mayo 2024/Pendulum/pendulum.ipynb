{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta notebook contiene bloques de código útiles para realizar Q-learning en el entorno \"Pendulum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pendulum_env_extended import PendulumEnvExtended\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PendulumEnvExtended(render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretización de los estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,\n",
       "        0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_space = np.linspace(-1, 1, 10)\n",
    "y_space = np.linspace(-1, 1, 10)\n",
    "vel_space = np.linspace(-8, 8, 100)\n",
    "x_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener el estado a partir de la observación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(obs):\n",
    "    x, y, vel = obs\n",
    "    x_bin = np.digitize(x, x_space)\n",
    "    y_bin = np.digitize(y, y_space)\n",
    "    vel_bin = np.digitize(vel, vel_space)\n",
    "    return x_bin, y_bin, vel_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6, 52)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = get_state(np.array([-0.4, 0.2, 0.3]))\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretización de las acciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.0,\n",
       " -1.5555555555555556,\n",
       " -1.1111111111111112,\n",
       " -0.6666666666666667,\n",
       " -0.22222222222222232,\n",
       " 0.22222222222222232,\n",
       " 0.6666666666666665,\n",
       " 1.1111111111111107,\n",
       " 1.5555555555555554,\n",
       " 2.0]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = list(np.linspace(-2, 2, 10))\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_action():\n",
    "    return random.choice(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicilización de la tabla Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = np.zeros((len(x_space) + 1, len(y_space) + 1, len(vel_space) + 1, len(actions)))\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtención de la acción a partir de la tabla Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_policy(state, Q):\n",
    "    action = actions[np.argmax(Q[state])]\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epsilon-Greedy Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(state, Q, epsilon=0.1):\n",
    "    explore = np.random.binomial(1, epsilon)\n",
    "    if explore:\n",
    "        action = get_sample_action()\n",
    "    # exploit\n",
    "    else:\n",
    "        action = optimal_policy(state, Q)\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de episodio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(obs):\n",
    "    x, y, vel = obs\n",
    "    x_bin = np.digitize(x, x_space)\n",
    "    y_bin = np.digitize(y, y_space)\n",
    "    vel_bin = np.digitize(vel, vel_space)\n",
    "    return x_bin, y_bin, vel_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemento Q Learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(env, num_episodes=5000, alpha=0.1, gamma=0.99, epsilon_start=1.0, epsilon_end=0.1, epsilon_decay=0.999):\n",
    "    Q = np.zeros((len(x_space) + 1, len(y_space) + 1, len(vel_space) + 1, len(actions)))\n",
    "    epsilon = epsilon_start\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        state = get_state(obs)\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        \n",
    "        while not done:\n",
    "            action = epsilon_greedy_policy(state, Q, epsilon)\n",
    "            action_idx = actions.index(action)\n",
    "            real_action = np.array([action])\n",
    "            obs, reward, done, _, _ = env.step(real_action)\n",
    "            next_state = get_state(obs)\n",
    "            next_action_idx = np.argmax(Q[next_state])\n",
    "            td_target = reward + gamma * Q[next_state][next_action_idx]\n",
    "            td_delta = td_target - Q[state][action_idx]\n",
    "            Q[state][action_idx] += alpha * td_delta\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "        \n",
    "        epsilon = max(epsilon_end, epsilon * epsilon_decay)  # Decaer epsilon\n",
    "        \n",
    "        if (episode + 1) % 100 == 0:\n",
    "            print(f\"Episode {episode + 1}/{num_episodes} - Total Reward: {total_reward}, Epsilon: {epsilon}\")\n",
    "    \n",
    "    return Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/10000 - Total Reward: -3948.7889837709085, Epsilon: 0.9047921471137096\n",
      "Episode 200/10000 - Total Reward: -4515.975054817654, Epsilon: 0.818648829478636\n",
      "Episode 300/10000 - Total Reward: -3357.307566612331, Epsilon: 0.7407070321560997\n",
      "Episode 400/10000 - Total Reward: -4633.162693526457, Epsilon: 0.6701859060067403\n",
      "Episode 500/10000 - Total Reward: -3243.1311690856855, Epsilon: 0.6063789448611848\n",
      "Episode 600/10000 - Total Reward: -2841.259012801881, Epsilon: 0.5486469074854965\n",
      "Episode 700/10000 - Total Reward: -5272.465468057276, Epsilon: 0.4964114134310989\n",
      "Episode 800/10000 - Total Reward: -4345.575508943294, Epsilon: 0.4491491486100748\n",
      "Episode 900/10000 - Total Reward: -5079.414342690447, Epsilon: 0.4063866225452039\n",
      "Episode 1000/10000 - Total Reward: -4546.537663265384, Epsilon: 0.3676954247709635\n",
      "Episode 1100/10000 - Total Reward: -3730.808498069549, Epsilon: 0.33268793286240766\n",
      "Episode 1200/10000 - Total Reward: -4014.8574392482037, Epsilon: 0.3010134290933992\n",
      "Episode 1300/10000 - Total Reward: -3372.524078486223, Epsilon: 0.27235458681947705\n",
      "Episode 1400/10000 - Total Reward: -3314.7981918524943, Epsilon: 0.24642429138466176\n",
      "Episode 1500/10000 - Total Reward: -4616.735810956617, Epsilon: 0.22296276370290227\n",
      "Episode 1600/10000 - Total Reward: -3495.2505018820107, Epsilon: 0.20173495769715546\n",
      "Episode 1700/10000 - Total Reward: -3085.327796869703, Epsilon: 0.18252820552270246\n",
      "Episode 1800/10000 - Total Reward: -3363.1774354761255, Epsilon: 0.1651500869836984\n",
      "Episode 1900/10000 - Total Reward: -2287.9959846431675, Epsilon: 0.14942650179799613\n",
      "Episode 2000/10000 - Total Reward: -3106.8043499710843, Epsilon: 0.1351999253974994\n",
      "Episode 2100/10000 - Total Reward: -2650.168776991395, Epsilon: 0.12232783079001676\n",
      "Episode 2200/10000 - Total Reward: -2610.8649436511073, Epsilon: 0.11068126067226178\n",
      "Episode 2300/10000 - Total Reward: -4855.806945012038, Epsilon: 0.10014353548890782\n",
      "Episode 2400/10000 - Total Reward: -3624.008280656792, Epsilon: 0.1\n",
      "Episode 2500/10000 - Total Reward: -2276.6305077710354, Epsilon: 0.1\n",
      "Episode 2600/10000 - Total Reward: -10.286583708543363, Epsilon: 0.1\n",
      "Episode 2700/10000 - Total Reward: -2561.4820311964977, Epsilon: 0.1\n",
      "Episode 2800/10000 - Total Reward: -3765.334659005676, Epsilon: 0.1\n",
      "Episode 2900/10000 - Total Reward: -3168.2315466053656, Epsilon: 0.1\n",
      "Episode 3000/10000 - Total Reward: -1207.54010016197, Epsilon: 0.1\n",
      "Episode 3100/10000 - Total Reward: -1017.2401951486274, Epsilon: 0.1\n",
      "Episode 3200/10000 - Total Reward: -2530.136924165321, Epsilon: 0.1\n",
      "Episode 3300/10000 - Total Reward: -1575.2825255456926, Epsilon: 0.1\n",
      "Episode 3400/10000 - Total Reward: -1985.887771710776, Epsilon: 0.1\n",
      "Episode 3500/10000 - Total Reward: -3392.215892357165, Epsilon: 0.1\n",
      "Episode 3600/10000 - Total Reward: -15.513337654867524, Epsilon: 0.1\n",
      "Episode 3700/10000 - Total Reward: -482.4003407388004, Epsilon: 0.1\n",
      "Episode 3800/10000 - Total Reward: -749.7739103547035, Epsilon: 0.1\n",
      "Episode 3900/10000 - Total Reward: -3137.383501324869, Epsilon: 0.1\n",
      "Episode 4000/10000 - Total Reward: -13.547932668151978, Epsilon: 0.1\n",
      "Episode 4100/10000 - Total Reward: -2716.9373922961404, Epsilon: 0.1\n",
      "Episode 4200/10000 - Total Reward: -1504.695027610903, Epsilon: 0.1\n",
      "Episode 4300/10000 - Total Reward: -2143.056429368531, Epsilon: 0.1\n",
      "Episode 4400/10000 - Total Reward: -251.71805929719375, Epsilon: 0.1\n",
      "Episode 4500/10000 - Total Reward: -1267.5283136370833, Epsilon: 0.1\n",
      "Episode 4600/10000 - Total Reward: -2470.2622268948912, Epsilon: 0.1\n",
      "Episode 4700/10000 - Total Reward: -518.3061205712215, Epsilon: 0.1\n",
      "Episode 4800/10000 - Total Reward: -1011.1958806029439, Epsilon: 0.1\n",
      "Episode 4900/10000 - Total Reward: -726.8729432774729, Epsilon: 0.1\n",
      "Episode 5000/10000 - Total Reward: -2190.644694527965, Epsilon: 0.1\n",
      "Episode 5100/10000 - Total Reward: -3059.001313063211, Epsilon: 0.1\n",
      "Episode 5200/10000 - Total Reward: -1734.721678306546, Epsilon: 0.1\n",
      "Episode 5300/10000 - Total Reward: -1368.9413970532198, Epsilon: 0.1\n",
      "Episode 5400/10000 - Total Reward: -1210.870514118032, Epsilon: 0.1\n",
      "Episode 5500/10000 - Total Reward: -621.271526861335, Epsilon: 0.1\n",
      "Episode 5600/10000 - Total Reward: -1751.6186838015233, Epsilon: 0.1\n",
      "Episode 5700/10000 - Total Reward: -137.8615279624146, Epsilon: 0.1\n",
      "Episode 5800/10000 - Total Reward: -137.539538359816, Epsilon: 0.1\n",
      "Episode 5900/10000 - Total Reward: -755.3394844080649, Epsilon: 0.1\n",
      "Episode 6000/10000 - Total Reward: -260.79052678745245, Epsilon: 0.1\n",
      "Episode 6100/10000 - Total Reward: -967.2815942792735, Epsilon: 0.1\n",
      "Episode 6200/10000 - Total Reward: -3512.12615066592, Epsilon: 0.1\n",
      "Episode 6300/10000 - Total Reward: -1362.6994748199786, Epsilon: 0.1\n",
      "Episode 6400/10000 - Total Reward: -3039.6221073524234, Epsilon: 0.1\n",
      "Episode 6500/10000 - Total Reward: -1053.003782631332, Epsilon: 0.1\n",
      "Episode 6600/10000 - Total Reward: -1638.1667043802483, Epsilon: 0.1\n",
      "Episode 6700/10000 - Total Reward: -1110.6739677819878, Epsilon: 0.1\n",
      "Episode 6800/10000 - Total Reward: -9.805843372341513, Epsilon: 0.1\n",
      "Episode 6900/10000 - Total Reward: -648.218324778446, Epsilon: 0.1\n",
      "Episode 7000/10000 - Total Reward: -1285.6408538985959, Epsilon: 0.1\n",
      "Episode 7100/10000 - Total Reward: -1005.2891307751678, Epsilon: 0.1\n",
      "Episode 7200/10000 - Total Reward: -2439.3538701285456, Epsilon: 0.1\n",
      "Episode 7300/10000 - Total Reward: -137.0222285127961, Epsilon: 0.1\n",
      "Episode 7400/10000 - Total Reward: -133.74073817351416, Epsilon: 0.1\n",
      "Episode 7500/10000 - Total Reward: -661.5541537645225, Epsilon: 0.1\n",
      "Episode 7600/10000 - Total Reward: -1024.2856370660766, Epsilon: 0.1\n",
      "Episode 7700/10000 - Total Reward: -1070.1829036307165, Epsilon: 0.1\n",
      "Episode 7800/10000 - Total Reward: -760.3322391443301, Epsilon: 0.1\n",
      "Episode 7900/10000 - Total Reward: -263.4036169781044, Epsilon: 0.1\n",
      "Episode 8000/10000 - Total Reward: -501.51006562426136, Epsilon: 0.1\n",
      "Episode 8100/10000 - Total Reward: -2267.627271850576, Epsilon: 0.1\n",
      "Episode 8200/10000 - Total Reward: -253.82439125935954, Epsilon: 0.1\n",
      "Episode 8300/10000 - Total Reward: -1025.4496799625665, Epsilon: 0.1\n",
      "Episode 8400/10000 - Total Reward: -880.8532105703509, Epsilon: 0.1\n",
      "Episode 8500/10000 - Total Reward: -248.44006253377876, Epsilon: 0.1\n",
      "Episode 8600/10000 - Total Reward: -370.17387334817215, Epsilon: 0.1\n",
      "Episode 8700/10000 - Total Reward: -1635.260172489351, Epsilon: 0.1\n",
      "Episode 8800/10000 - Total Reward: -1206.0356999179785, Epsilon: 0.1\n",
      "Episode 8900/10000 - Total Reward: -1387.8972479048425, Epsilon: 0.1\n",
      "Episode 9000/10000 - Total Reward: -761.9875334729464, Epsilon: 0.1\n",
      "Episode 9100/10000 - Total Reward: -135.01619087691228, Epsilon: 0.1\n",
      "Episode 9200/10000 - Total Reward: -135.58306383979988, Epsilon: 0.1\n",
      "Episode 9300/10000 - Total Reward: -389.0777343482496, Epsilon: 0.1\n",
      "Episode 9400/10000 - Total Reward: -722.0215739043624, Epsilon: 0.1\n",
      "Episode 9500/10000 - Total Reward: -139.0140217728553, Epsilon: 0.1\n",
      "Episode 9600/10000 - Total Reward: -1590.8213602681317, Epsilon: 0.1\n",
      "Episode 9700/10000 - Total Reward: -257.5888042880533, Epsilon: 0.1\n",
      "Episode 9800/10000 - Total Reward: -1147.5689124476232, Epsilon: 0.1\n",
      "Episode 9900/10000 - Total Reward: -136.24150804780768, Epsilon: 0.1\n",
      "Episode 10000/10000 - Total Reward: -594.504220294349, Epsilon: 0.1\n"
     ]
    }
   ],
   "source": [
    "Q = q_learning(env, num_episodes=10000, alpha=0.1, gamma=0.99, epsilon_start=1.0, epsilon_end=0.1, epsilon_decay=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(env, Q, num_episodes=100):\n",
    "    total_rewards = []\n",
    "    for episode in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        state = get_state(obs)\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        \n",
    "        while not done:\n",
    "            action_idx = np.argmax(Q[state])\n",
    "            action = actions[action_idx]\n",
    "            real_action = np.array([action])\n",
    "            obs, reward, done, _, _ = env.step(real_action)\n",
    "            state = get_state(obs)\n",
    "            total_reward += reward\n",
    "        \n",
    "        total_rewards.append(total_reward)\n",
    "    \n",
    "    average_reward = np.mean(total_rewards)\n",
    "    print(f\"Average Reward over {num_episodes} episodes: {average_reward}\")\n",
    "    return average_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward over 100 episodes: -865.8959008248903\n"
     ]
    }
   ],
   "source": [
    "average_reward = evaluate_policy(env, Q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
